{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad821f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import datetime\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    param = {\n",
    "        \"objective\": 'binary:logistic',\n",
    "        'reg_lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "        'gamma':trial.suggest_loguniform('gamma', 1e-3,1),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [i/10.0 for i in range(4,11)]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [i/10.0 for i in range(4,11)]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01,0.012,0.014,0.016,0.018, 0.02,0.300000012]),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',100,500),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [5,6,7,9,11,13,15,17,20]),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "    }\n",
    "    model = xgb.XGBClassifier(**param)  \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a70a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_samples=500, n_features=15, n_informative=15, n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2,class_sep=0.75,flip_y=0,weights=[0.5,0.5], random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468a6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://saturncloud.io/docs/examples/machinelearning/xgboost-training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a55a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 61167 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060586d09c464613bf0f850437639e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>LocalCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dask.array as da\n",
    "import xgboost as xgb\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_ml.metrics import mean_absolute_error\n",
    "\n",
    "cluster = dask.distributed.LocalCluster(n_workers=2, threads_per_worker=1)\n",
    "client = dask.distributed.Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b821782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "184d2095",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_delayed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-d8ad3b9c93d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\dask_xgboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, eval_set, sample_weight, sample_weight_eval_set, eval_metric, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m         )\n\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\dask_xgboost\\core.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(client, params, data, labels, dmatrix_kwargs, evals_result, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     )\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36msync\u001b[1;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             return sync(\n\u001b[1;32m--> 844\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m             )\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\utils.py\u001b[0m in \u001b[0;36msync\u001b[1;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\utils.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0merror\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\tornado\\gen.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m                         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\tornado\\gen.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# performance penalty for the synchronous case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                     \u001b[0myielded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReturn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                     future_set_result_unless_cancelled(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\dask_xgboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(client, params, data, labels, dmatrix_kwargs, evals_result, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# Break apart Dask.array/dataframe into chunks/parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mdata_parts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_delayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[0mlabel_parts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_delayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_delayed'"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "# df = dd.read_parquet('s3://...')\n",
    "\n",
    "# # Split into training and testing data\n",
    "# train, test = df.random_split([0.8, 0.2])\n",
    "\n",
    "# # Separate labels from data\n",
    "# train_labels = train.x > 0\n",
    "# test_labels = test.x > 0\n",
    "\n",
    "# del train['x']  # remove informative column from data\n",
    "# del test['x']  # remove informative column from data\n",
    "\n",
    "from xgboost import XGBRegressor  # change import\n",
    "from dask_ml.xgboost import XGBRegressor\n",
    "\n",
    "est = XGBRegressor()\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "prediction = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "318c5524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 62391 instead\n",
      "  http_address[\"port\"], self.http_server.port\n",
      "distributed.worker - WARNING - Compute Failed\n",
      "Function:  fit_and_score\n",
      "args:      (XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), <dask_ml.model_selection.methods.CVCache object at 0x0000016C4032B388>, array([[-2.38798738e+00, -9.00069207e-01],\n",
      "       [ 6.17897478e-01, -7.73979522e-01],\n",
      "       [-4.73088823e-01,  2.99055609e-01],\n",
      "       [-2.34716136e+00, -2.12007027e-01],\n",
      "       [ 1.86939989e+00, -3.42674565e-01],\n",
      "       [ 6.64669193e-01,  9.02243816e-01],\n",
      "       [-6.03423647e-01, -1.14953052\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'numpy.ndarray' object has no attribute 'unique'\")\n",
      "\n",
      "distributed.worker - WARNING - Compute Failed\n",
      "Function:  fit_and_score\n",
      "args:      (XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), <dask_ml.model_selection.methods.CVCache object at 0x0000016C4032B388>, array([[-2.38798738e+00, -9.00069207e-01],\n",
      "       [ 6.17897478e-01, -7.73979522e-01],\n",
      "       [-4.73088823e-01,  2.99055609e-01],\n",
      "       [-2.34716136e+00, -2.12007027e-01],\n",
      "       [ 1.86939989e+00, -3.42674565e-01],\n",
      "       [ 6.64669193e-01,  9.02243816e-01],\n",
      "       [-6.03423647e-01, -1.14953052\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'numpy.ndarray' object has no attribute 'unique'\")\n",
      "\n",
      "distributed.worker - WARNING - Compute Failed\n",
      "Function:  fit_and_score\n",
      "args:      (XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), <dask_ml.model_selection.methods.CVCache object at 0x0000016C4032B388>, array([[-2.38798738e+00, -9.00069207e-01],\n",
      "       [ 6.17897478e-01, -7.73979522e-01],\n",
      "       [-4.73088823e-01,  2.99055609e-01],\n",
      "       [-2.34716136e+00, -2.12007027e-01],\n",
      "       [ 1.86939989e+00, -3.42674565e-01],\n",
      "       [ 6.64669193e-01,  9.02243816e-01],\n",
      "       [-6.03423647e-01, -1.14953052\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'numpy.ndarray' object has no attribute 'unique'\")\n",
      "\n",
      "distributed.worker - WARNING - Compute Failed\n",
      "Function:  fit_and_score\n",
      "args:      (XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), <dask_ml.model_selection.methods.CVCache object at 0x0000016C4032B388>, array([[-2.38798738e+00, -9.00069207e-01],\n",
      "       [ 6.17897478e-01, -7.73979522e-01],\n",
      "       [-4.73088823e-01,  2.99055609e-01],\n",
      "       [-2.34716136e+00, -2.12007027e-01],\n",
      "       [ 1.86939989e+00, -3.42674565e-01],\n",
      "       [ 6.64669193e-01,  9.02243816e-01],\n",
      "       [-6.03423647e-01, -1.14953052\n",
      "kwargs:    {}\n",
      "Exception: AttributeError(\"'numpy.ndarray' object has no attribute 'unique'\")\n",
      "\n",
      "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 0, 0) has failed... retrying\n",
      "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 0, 1) has failed... retrying\n",
      "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 1, 0) has failed... retrying\n",
      "distributed.worker - ERROR - ('error', 'waiting')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1502, in add_task\n",
      "    self.transition(ts, \"waiting\", runspec=runspec)\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1602, in transition\n",
      "    func = self._transitions[start, finish]\n",
      "KeyError: ('error', 'waiting')\n",
      "distributed.core - ERROR - ('error', 'waiting')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1502, in add_task\n",
      "    self.transition(ts, \"waiting\", runspec=runspec)\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1602, in transition\n",
      "    func = self._transitions[start, finish]\n",
      "KeyError: ('error', 'waiting')\n",
      "distributed.worker - ERROR - ('error', 'waiting')\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1000, in handle_scheduler\n",
      "    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1502, in add_task\n",
      "    self.transition(ts, \"waiting\", runspec=runspec)\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1602, in transition\n",
      "    func = self._transitions[start, finish]\n",
      "KeyError: ('error', 'waiting')\n",
      "tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <zmq.eventloop.ioloop.ZMQIOLoop object at 0x0000016C40219E08>>, <Task finished coro=<Worker.handle_scheduler() done, defined at C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py:997> exception=KeyError(('error', 'waiting'))>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\tornado\\ioloop.py\", line 765, in _discard_future_result\n",
      "    future.result()\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1000, in handle_scheduler\n",
      "    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\core.py\", line 573, in handle_stream\n",
      "    handler(**merge(extra, msg))\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1502, in add_task\n",
      "    self.transition(ts, \"waiting\", runspec=runspec)\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\worker.py\", line 1602, in transition\n",
      "    func = self._transitions[start, finish]\n",
      "KeyError: ('error', 'waiting')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dask_ml.model_selection._search:('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 1, 1) has failed... retrying\n",
      "WARNING:dask_ml.model_selection._search:cv-n-samples-db69da5b1e6bba4675cc50adc60d08f2 has failed... retrying\n",
      "distributed.utils - ERROR - \"('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 0, 0)\"\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\utils.py\", line 668, in log_errors\n",
      "    yield\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\scheduler.py\", line 3986, in add_worker\n",
      "    typename=types[key],\n",
      "KeyError: \"('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 0, 0)\"\n",
      "distributed.core - ERROR - Exception while handling op register-worker\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\core.py\", line 501, in handle_comm\n",
      "    result = await result\n",
      "  File \"C:\\Users\\004567\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\scheduler.py\", line 3986, in add_worker\n",
      "    typename=types[key],\n",
      "KeyError: \"('xgbclassifier-fit-score-db69da5b1e6bba4675cc50adc60d08f2', 0, 0)\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-2f93083d77f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m clf = dcv.GridSearchCV(dask_xgboost.XGBClassifier(), params, cv=sklearn.model_selection.KFold(n_splits=2),\n\u001b[0;32m     15\u001b[0m                        scoring='neg_mean_squared_error', scheduler=client)\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\dask_ml\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mresult_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m             \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"finished\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36mbatches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4400\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4401\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4402\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4403\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4404\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   4372\u001b[0m         \"\"\"\n\u001b[0;32m   4373\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4374\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4375\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4376\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4333\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4334\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4335\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4336\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_and_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\root3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask_ml.model_selection as dcv\n",
    "import dask_xgboost\n",
    "import sklearn.model_selection\n",
    "from distributed import Client\n",
    "\n",
    "client = Client(processes=False)\n",
    "\n",
    "x = np.random.randn(100, 2)\n",
    "y = np.random.randint(0, 1, 100)\n",
    "\n",
    "params = {'max_depth': [2, 3]}\n",
    "\n",
    "clf = dcv.GridSearchCV(dask_xgboost.XGBClassifier(), params, cv=sklearn.model_selection.KFold(n_splits=2),\n",
    "                       scoring='neg_mean_squared_error', scheduler=client)\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb9d69eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.1422595977783203\n"
     ]
    }
   ],
   "source": [
    "# evaluate the effect of the number of threads\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from matplotlib import pyplot\n",
    "\n",
    "start = time.time()\n",
    "model = XGBClassifier(nthread=-1)\n",
    "model.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b21fa3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.2745633125305176\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e285d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/best-tune-multithreading-support-xgboost-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa58fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4cabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fdf6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a693d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "493b1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "import pandas as pd\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "# model = xgb.XGBClassifier()  \n",
    "# model.fit(X_train, y_train)\n",
    "# preds = model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, preds)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.RandomSampler(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d390194",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db247cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp1 = random_study.trials_dataframe()['datetime_complete'].min()\n",
    "tstamp2 = random_study.trials_dataframe()['datetime_complete'].max()\n",
    "\n",
    "tstamp1 - tstamp2 if tstamp1 > tstamp2 else tstamp2 - tstamp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0705290",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476a00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    ")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e216df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp1 = study.trials_dataframe()['datetime_complete'].min()\n",
    "tstamp2 = study.trials_dataframe()['datetime_complete'].max()\n",
    "\n",
    "tstamp1 - tstamp2 if tstamp1 > tstamp2 else tstamp2 - tstamp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d748b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
